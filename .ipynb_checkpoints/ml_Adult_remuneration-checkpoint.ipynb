{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Adult remuneration\n",
    "\n",
    "Based on the Adult dataset (https://archive.ics.uci.edu/ml/datasets/adult), we'll use Random Forest to determine if a adult receives anually greater or less than 50k.\n",
    "\n",
    "SOURCE: \n",
    "- Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "- Michael Greenacre, Jörg Blasius (2006). Multiple Correspondence Analysis and Related Methods, CRC Press. ISBN 1584886285."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Integrantes #####\n",
    "    Alex Lan                                \n",
    "    Amanda Maria Martins Funabashi                  \n",
    "    Samyr Abrahão Moises                            \n",
    "    Waldyr Lourenço de Freitas Junior               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Road Map\n",
    "1. Full Dataset\n",
    "2. Multiple Correspondence Analysis (MCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-folds Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold(ds_orig, k):\n",
    "\n",
    "    \n",
    "    bold = \"\\033[1m\"\n",
    "    reset = \"\\033[0;0m\"\n",
    "    print(bold + f'Número de K: {k}' + reset)\n",
    "    print('\\n')\n",
    "    data_dict = {}\n",
    "\n",
    "    #Divide o DataSet original em dois DataSets, um para cada classe\n",
    "    ds_class1 = ds_orig[ds_orig[ds_orig.columns[-1]]==ds_orig.iloc[:,-1].unique()[0]]\n",
    "    ds_class2 = ds_orig[ds_orig[ds_orig.columns[-1]]==ds_orig.iloc[:,-1].unique()[1]]\n",
    "    \n",
    "    #Armazena a quantidade inteira de instâncias para cada k\n",
    "    n_inst1 = int(ds_class1.iloc[:,-1].count()/k)\n",
    "    n_inst2 = int(ds_class2.iloc[:,-1].count()/k)\n",
    "    \n",
    "    #Armazena o resto da divisão acima para facilitar a divisão de forma que cada parte tenha no máximo 1 elemento de diferença\n",
    "    n_inst_err1 = ds_class1.iloc[:,-1].count()%k\n",
    "    n_inst_err2 = ds_class2.iloc[:,-1].count()%k\n",
    "    \n",
    "    #Geração dos DataSets\n",
    "    range_fim1 = 0\n",
    "    range_fim2 = 0\n",
    "    for itr in range(k):\n",
    "        \n",
    "        #Cálculo do range do DataSet da classe 1\n",
    "        if(n_inst_err1 != 0):\n",
    "            range_ini1 = range_fim1\n",
    "            range_fim1 = range_fim1 + n_inst1 + 1\n",
    "            n_inst_err1 = n_inst_err1 - 1\n",
    "        else:\n",
    "            range_ini1 = range_fim1\n",
    "            range_fim1 = range_fim1 + n_inst1\n",
    "            \n",
    "        #Cálculo do range do DataSet da classe 2\n",
    "        if(n_inst_err2 != 0):\n",
    "            range_ini2 = range_fim2\n",
    "            range_fim2 = range_fim2 + n_inst2 + 1\n",
    "            n_inst_err2 = n_inst_err2 - 1\n",
    "        else:\n",
    "            range_ini2 = range_fim2\n",
    "            range_fim2 = range_fim2 + n_inst2\n",
    "            \n",
    "        #Geração de subDataSets de acordo com o range acima\n",
    "        data_temp1 = ds_class1.iloc[range_ini1:range_fim1]\n",
    "        data_temp2 = ds_class2.iloc[range_ini2:range_fim2]\n",
    "        \n",
    "        #Concatenação dos subDataSets de classes distintas para um único subDataSet\n",
    "        data_write = pd.concat([data_temp1, data_temp2])\n",
    "        \n",
    "        #Gravação do arquivo em disco (Comentado temporariamente, pois fará parte de outra atividade)\n",
    "        #filename = 'subDataSet' + str(itr) + '.csv'\n",
    "        #data_write.to_csv(f'C:\\\\{filename}',header=False)\n",
    "        \n",
    "        #Gravação dos subdatasets em um dicionário de objetos\n",
    "        data_dict[itr] = data_write\n",
    "    return data_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(data_dict, classifier):\n",
    "    # for de dentro define quem eh o conjunto de treinamento\n",
    "    # e concatena os subdatasets para formar o cjto treinamento\n",
    "    start_time = time.time()\n",
    "    precisao = 0\n",
    "    recall = 0 \n",
    "    acuracia = 0\n",
    "    k = len(kfold_dicts)\n",
    "    for itr2 in range(0, len(kfold_dicts)):\n",
    "        test = data_dict[itr2]\n",
    "                      \n",
    "        train = None\n",
    "        for itr3 in range(0, len(kfold_dicts)):\n",
    "            if(itr3 != itr2):\n",
    "                train = pd.concat([train,data_dict[itr3]])\n",
    "        #execucao do classificador e predicao dos resultados\n",
    "        classifier.fit(train.iloc[:,:-1], train.iloc[:,-1])\n",
    "        y_pred = classifier.predict(test.iloc[:,:-1])\n",
    "        \n",
    "        #Precisão:\n",
    "        #print(\"Precision:\",round(metrics.precision_score(test.iloc[:,-1], y_pred),3))\n",
    "        precisao = precisao + precision_score(test.iloc[:,-1], y_pred)\n",
    "        #Erro:\n",
    "        #print(\"Recall:\",round(metrics.recall_score(test.iloc[:,-1], y_pred),3))\n",
    "        recall = recall + recall_score(test.iloc[:,-1], y_pred)\n",
    "        #Acurácia: \n",
    "        #print(\"Accuracy:\",round(metrics.accuracy_score(test.iloc[:,-1], y_pred),3))\n",
    "        acuracia = acuracia + accuracy_score(test.iloc[:,-1], y_pred)\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "    print(\"Precision:\", round(precisao/k,5))\n",
    "    print(\"Recall:\", round(recall/k,5))\n",
    "    #print(\"Erro:\", round(mse/k,5))\n",
    "    print(\"Accuracy:\", round(acuracia/k,5))\n",
    "    print(\"--- %s time ---\" % (time.time() - start_time))\n",
    "    return precisao/k, recall/k, acuracia/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBS. Para o MCA, mudamos alguns parametros pois o numero de caracteristicas que consideramos nesse caso é de apenas 3.\n",
    "# numero de arvores da random forest.\n",
    "n_estimators = [5,10,50,100,500]\n",
    "\n",
    "# numero maximo de caracteristicas a considerar.\n",
    "max_features = [1,2,3]\n",
    "\n",
    "# profundidade maxima das arvores\n",
    "max_depth = [4,6,8,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome Arquivo Origem: adult_train_33.1_Label_Encoded.csv\n"
     ]
    }
   ],
   "source": [
    "# Nome do Dataset de Entrada\n",
    "ds_nome = 'adult_train_33.1'\n",
    "\n",
    "#Notebook 01-pre-proc_tratamento_base.ipynb prepara dados preciamente\n",
    "ds_pre_proc = '_Label_Encoded'\n",
    "ds_tipo = '.csv'\n",
    "ds_full_name = ds_nome + ds_pre_proc + ds_tipo\n",
    "\n",
    "print(\"Nome Arquivo Origem: {0}\".format(ds_full_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(ds_full_name, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10034, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7542\n",
       "1    2492\n",
       "Name: sal, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNúmero de K: 3\u001b[0;0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_dicts = kFold(train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.777\n",
      "Recall: 0.18417\n",
      "Accuracy: 0.78423\n",
      "--- 0.2035219669342041 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.72969\n",
      "Recall: 0.36878\n",
      "Accuracy: 0.80895\n",
      "--- 0.15745139122009277 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.71492\n",
      "Recall: 0.4045\n",
      "Accuracy: 0.81174\n",
      "--- 0.14402461051940918 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.73218\n",
      "Recall: 0.34712\n",
      "Accuracy: 0.80596\n",
      "--- 0.12166857719421387 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.72059\n",
      "Recall: 0.41613\n",
      "Accuracy: 0.81493\n",
      "--- 0.14560365676879883 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.66829\n",
      "Recall: 0.50042\n",
      "Accuracy: 0.81294\n",
      "--- 0.1456453800201416 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.72132\n",
      "Recall: 0.41776\n",
      "Accuracy: 0.81533\n",
      "--- 0.12726545333862305 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.70438\n",
      "Recall: 0.47432\n",
      "Accuracy: 0.82001\n",
      "--- 0.2103283405303955 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.70961\n",
      "Recall: 0.45264\n",
      "Accuracy: 0.81802\n",
      "--- 0.2341623306274414 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.70689\n",
      "Recall: 0.47392\n",
      "Accuracy: 0.82041\n",
      "--- 0.18895411491394043 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.68247\n",
      "Recall: 0.51244\n",
      "Accuracy: 0.81951\n",
      "--- 0.19917535781860352 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.67918\n",
      "Recall: 0.5269\n",
      "Accuracy: 0.82061\n",
      "--- 0.20705628395080566 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.7968\n",
      "Recall: 0.24319\n",
      "Accuracy: 0.79589\n",
      "--- 0.2441542148590088 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.73652\n",
      "Recall: 0.32746\n",
      "Accuracy: 0.80407\n",
      "--- 0.220078706741333 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.73986\n",
      "Recall: 0.36917\n",
      "Accuracy: 0.81084\n",
      "--- 0.23189854621887207 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.74358\n",
      "Recall: 0.31337\n",
      "Accuracy: 0.80118\n",
      "--- 0.22311758995056152 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.73152\n",
      "Recall: 0.41132\n",
      "Accuracy: 0.81632\n",
      "--- 0.2594587802886963 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.72537\n",
      "Recall: 0.41894\n",
      "Accuracy: 0.81622\n",
      "--- 0.2817199230194092 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.72933\n",
      "Recall: 0.40771\n",
      "Accuracy: 0.81533\n",
      "--- 0.23804283142089844 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.70909\n",
      "Recall: 0.49398\n",
      "Accuracy: 0.8239\n",
      "--- 0.3366539478302002 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.69655\n",
      "Recall: 0.47873\n",
      "Accuracy: 0.81872\n",
      "--- 0.36170196533203125 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.70126\n",
      "Recall: 0.47673\n",
      "Accuracy: 0.81951\n",
      "--- 0.30707383155822754 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.69309\n",
      "Recall: 0.50442\n",
      "Accuracy: 0.82141\n",
      "--- 0.4116218090057373 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.68975\n",
      "Recall: 0.50242\n",
      "Accuracy: 0.82011\n",
      "--- 0.4595639705657959 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.82084\n",
      "Recall: 0.20707\n",
      "Accuracy: 0.79171\n",
      "--- 1.4232490062713623 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.74584\n",
      "Recall: 0.35153\n",
      "Accuracy: 0.80905\n",
      "--- 1.2873320579528809 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.72459\n",
      "Recall: 0.37962\n",
      "Accuracy: 0.80995\n",
      "--- 1.3607158660888672 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.77052\n",
      "Recall: 0.32264\n",
      "Accuracy: 0.80775\n",
      "--- 0.9761977195739746 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.73726\n",
      "Recall: 0.40128\n",
      "Accuracy: 0.81583\n",
      "--- 1.0369913578033447 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.73161\n",
      "Recall: 0.42255\n",
      "Accuracy: 0.81802\n",
      "--- 1.2979950904846191 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.74478\n",
      "Recall: 0.40209\n",
      "Accuracy: 0.81722\n",
      "--- 1.1107141971588135 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.72595\n",
      "Recall: 0.46309\n",
      "Accuracy: 0.8232\n",
      "--- 1.0933337211608887 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.71456\n",
      "Recall: 0.48877\n",
      "Accuracy: 0.8245\n",
      "--- 1.5243453979492188 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.72241\n",
      "Recall: 0.45947\n",
      "Accuracy: 0.82191\n",
      "--- 1.5201342105865479 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.7028\n",
      "Recall: 0.50964\n",
      "Accuracy: 0.8246\n",
      "--- 1.5056865215301514 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.69688\n",
      "Recall: 0.52569\n",
      "Accuracy: 0.82529\n",
      "--- 1.6215710639953613 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.82528\n",
      "Recall: 0.20506\n",
      "Accuracy: 0.79181\n",
      "--- 1.793694257736206 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.7467\n",
      "Recall: 0.33788\n",
      "Accuracy: 0.80666\n",
      "--- 1.9600772857666016 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.72837\n",
      "Recall: 0.38443\n",
      "Accuracy: 0.81144\n",
      "--- 2.0268993377685547 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.77707\n",
      "Recall: 0.32384\n",
      "Accuracy: 0.80885\n",
      "--- 1.9214866161346436 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.7474\n",
      "Recall: 0.39727\n",
      "Accuracy: 0.81682\n",
      "--- 2.10746169090271 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.72857\n",
      "Recall: 0.42336\n",
      "Accuracy: 0.81752\n",
      "--- 2.4094889163970947 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.75238\n",
      "Recall: 0.40049\n",
      "Accuracy: 0.81842\n",
      "--- 2.0720136165618896 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.72743\n",
      "Recall: 0.4671\n",
      "Accuracy: 0.8242\n",
      "--- 2.40700626373291 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.71692\n",
      "Recall: 0.49358\n",
      "Accuracy: 0.82579\n",
      "--- 2.858511209487915 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.72785\n",
      "Recall: 0.4659\n",
      "Accuracy: 0.8241\n",
      "--- 2.406764030456543 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.70777\n",
      "Recall: 0.50884\n",
      "Accuracy: 0.82569\n",
      "--- 2.940033197402954 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.70245\n",
      "Recall: 0.52288\n",
      "Accuracy: 0.82639\n",
      "--- 2.9779577255249023 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.81629\n",
      "Recall: 0.20024\n",
      "Accuracy: 0.79011\n",
      "--- 8.236693143844604 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.74458\n",
      "Recall: 0.34832\n",
      "Accuracy: 0.80835\n",
      "--- 9.355837106704712 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.72912\n",
      "Recall: 0.38163\n",
      "Accuracy: 0.81114\n",
      "--- 10.46195101737976 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.76772\n",
      "Recall: 0.32464\n",
      "Accuracy: 0.80765\n",
      "--- 10.36381196975708 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.74316\n",
      "Recall: 0.38925\n",
      "Accuracy: 0.81483\n",
      "--- 11.787155151367188 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.72805\n",
      "Recall: 0.41052\n",
      "Accuracy: 0.81543\n",
      "--- 10.147300481796265 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.75456\n",
      "Recall: 0.39526\n",
      "Accuracy: 0.81782\n",
      "--- 9.183288812637329 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.73158\n",
      "Recall: 0.45426\n",
      "Accuracy: 0.823\n",
      "--- 11.430095434188843 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.71895\n",
      "Recall: 0.49318\n",
      "Accuracy: 0.82619\n",
      "--- 12.717101097106934 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.72777\n",
      "Recall: 0.4675\n",
      "Accuracy: 0.8243\n",
      "--- 12.248922348022461 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.71556\n",
      "Recall: 0.50803\n",
      "Accuracy: 0.82759\n",
      "--- 11.667890310287476 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.69586\n",
      "Recall: 0.53291\n",
      "Accuracy: 0.82589\n",
      "--- 12.25504732131958 time ---\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "columns = ['n_estimators', 'max_depth', 'max_features', 'precision', 'recall', 'acuracia']\n",
    "res = pd.DataFrame(columns = columns)\n",
    "best_precision = {'score': 0, 'model': None}\n",
    "best_recall = {'score': 0, 'model': None}\n",
    "best_accuracy = {'score': 0, 'model': None}\n",
    "\n",
    "for i_ne in range(0, len(n_estimators)):\n",
    "    for i_md in range(0, len(max_depth)):\n",
    "        for i_mf in range(0, len(max_features)):\n",
    "            print(\"n_estimators: \", n_estimators[i_ne])\n",
    "            print(\"max_depth: \", max_depth[i_md])\n",
    "            print(\"max_features: \", max_features[i_mf])\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators[i_ne], max_depth=max_depth[i_md], max_features=max_features[i_mf])\n",
    "\n",
    "            precision, recall, acuracia = classification(kfold_dicts, model)\n",
    "            if precision > best_precision['score']:\n",
    "                best_precision['score'] = precision\n",
    "                best_precision['model'] = model\n",
    "            if recall > best_recall['score']:\n",
    "                best_recall['score'] = recall\n",
    "                best_recall['model'] = model\n",
    "            if acuracia > best_accuracy['score']:\n",
    "                best_accuracy['score'] = acuracia\n",
    "                best_accuracy['model'] = model\n",
    "            res = pd.concat([res, pd.DataFrame([[n_estimators[i_ne], max_depth[i_md], max_features[i_mf],\n",
    "                                                 precision, recall, acuracia]], columns = columns)]) \n",
    "            #res = pd.concat([res, pd.DataFrame([n_estimators[i_ne],max_features[i_mf],precision, recall, acuracia], columns = columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>acuracia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776998</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.784233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.729691</td>\n",
       "      <td>0.368779</td>\n",
       "      <td>0.808950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714924</td>\n",
       "      <td>0.404498</td>\n",
       "      <td>0.811740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732175</td>\n",
       "      <td>0.347122</td>\n",
       "      <td>0.805960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720594</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.814929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.668289</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>0.812936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721316</td>\n",
       "      <td>0.417763</td>\n",
       "      <td>0.815329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704378</td>\n",
       "      <td>0.474325</td>\n",
       "      <td>0.820012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709610</td>\n",
       "      <td>0.452638</td>\n",
       "      <td>0.818018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706889</td>\n",
       "      <td>0.473925</td>\n",
       "      <td>0.820411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682465</td>\n",
       "      <td>0.512440</td>\n",
       "      <td>0.819514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.679180</td>\n",
       "      <td>0.526900</td>\n",
       "      <td>0.820610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796796</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>0.795895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.736519</td>\n",
       "      <td>0.327463</td>\n",
       "      <td>0.804067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.739856</td>\n",
       "      <td>0.369172</td>\n",
       "      <td>0.810843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.313374</td>\n",
       "      <td>0.801176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731517</td>\n",
       "      <td>0.411325</td>\n",
       "      <td>0.816325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.725369</td>\n",
       "      <td>0.418945</td>\n",
       "      <td>0.816225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729327</td>\n",
       "      <td>0.407709</td>\n",
       "      <td>0.815328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.709094</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.823899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696547</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.818716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701263</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>0.819514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693085</td>\n",
       "      <td>0.504419</td>\n",
       "      <td>0.821408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.689754</td>\n",
       "      <td>0.502418</td>\n",
       "      <td>0.820112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820838</td>\n",
       "      <td>0.207072</td>\n",
       "      <td>0.791709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745840</td>\n",
       "      <td>0.351529</td>\n",
       "      <td>0.809050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724587</td>\n",
       "      <td>0.379621</td>\n",
       "      <td>0.809947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770523</td>\n",
       "      <td>0.322639</td>\n",
       "      <td>0.807754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737264</td>\n",
       "      <td>0.401284</td>\n",
       "      <td>0.815826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731611</td>\n",
       "      <td>0.422553</td>\n",
       "      <td>0.818019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744778</td>\n",
       "      <td>0.402094</td>\n",
       "      <td>0.817222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.463092</td>\n",
       "      <td>0.823202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714565</td>\n",
       "      <td>0.488771</td>\n",
       "      <td>0.824497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722410</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.821906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702803</td>\n",
       "      <td>0.509643</td>\n",
       "      <td>0.824597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696882</td>\n",
       "      <td>0.525688</td>\n",
       "      <td>0.825294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825278</td>\n",
       "      <td>0.205055</td>\n",
       "      <td>0.791808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.746701</td>\n",
       "      <td>0.337876</td>\n",
       "      <td>0.806658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728374</td>\n",
       "      <td>0.384435</td>\n",
       "      <td>0.811441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.323838</td>\n",
       "      <td>0.808850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747404</td>\n",
       "      <td>0.397271</td>\n",
       "      <td>0.816823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728565</td>\n",
       "      <td>0.423363</td>\n",
       "      <td>0.817521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752378</td>\n",
       "      <td>0.400491</td>\n",
       "      <td>0.818418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727428</td>\n",
       "      <td>0.467101</td>\n",
       "      <td>0.824198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716922</td>\n",
       "      <td>0.493583</td>\n",
       "      <td>0.825792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727853</td>\n",
       "      <td>0.465895</td>\n",
       "      <td>0.824098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707771</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.825693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>0.522877</td>\n",
       "      <td>0.826390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816286</td>\n",
       "      <td>0.200245</td>\n",
       "      <td>0.790114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744585</td>\n",
       "      <td>0.348320</td>\n",
       "      <td>0.808352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.729122</td>\n",
       "      <td>0.381626</td>\n",
       "      <td>0.811142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.324642</td>\n",
       "      <td>0.807654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.743157</td>\n",
       "      <td>0.389247</td>\n",
       "      <td>0.814830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.410517</td>\n",
       "      <td>0.815428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754561</td>\n",
       "      <td>0.395263</td>\n",
       "      <td>0.817820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731583</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.823002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.718955</td>\n",
       "      <td>0.493184</td>\n",
       "      <td>0.826191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727772</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.824298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.715564</td>\n",
       "      <td>0.508031</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695855</td>\n",
       "      <td>0.532912</td>\n",
       "      <td>0.825892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators max_depth max_features  precision    recall  acuracia\n",
       "0            5         4            1   0.776998  0.184174  0.784233\n",
       "0            5         4            2   0.729691  0.368779  0.808950\n",
       "0            5         4            3   0.714924  0.404498  0.811740\n",
       "0            5         6            1   0.732175  0.347122  0.805960\n",
       "0            5         6            2   0.720594  0.416132  0.814929\n",
       "0            5         6            3   0.668289  0.500424  0.812936\n",
       "0            5         8            1   0.721316  0.417763  0.815329\n",
       "0            5         8            2   0.704378  0.474325  0.820012\n",
       "0            5         8            3   0.709610  0.452638  0.818018\n",
       "0            5        10            1   0.706889  0.473925  0.820411\n",
       "0            5        10            2   0.682465  0.512440  0.819514\n",
       "0            5        10            3   0.679180  0.526900  0.820610\n",
       "0           10         4            1   0.796796  0.243190  0.795895\n",
       "0           10         4            2   0.736519  0.327463  0.804067\n",
       "0           10         4            3   0.739856  0.369172  0.810843\n",
       "0           10         6            1   0.743580  0.313374  0.801176\n",
       "0           10         6            2   0.731517  0.411325  0.816325\n",
       "0           10         6            3   0.725369  0.418945  0.816225\n",
       "0           10         8            1   0.729327  0.407709  0.815328\n",
       "0           10         8            2   0.709094  0.493976  0.823899\n",
       "0           10         8            3   0.696547  0.478728  0.818716\n",
       "0           10        10            1   0.701263  0.476732  0.819514\n",
       "0           10        10            2   0.693085  0.504419  0.821408\n",
       "0           10        10            3   0.689754  0.502418  0.820112\n",
       "0           50         4            1   0.820838  0.207072  0.791709\n",
       "0           50         4            2   0.745840  0.351529  0.809050\n",
       "0           50         4            3   0.724587  0.379621  0.809947\n",
       "0           50         6            1   0.770523  0.322639  0.807754\n",
       "0           50         6            2   0.737264  0.401284  0.815826\n",
       "0           50         6            3   0.731611  0.422553  0.818019\n",
       "0           50         8            1   0.744778  0.402094  0.817222\n",
       "0           50         8            2   0.725951  0.463092  0.823202\n",
       "0           50         8            3   0.714565  0.488771  0.824497\n",
       "0           50        10            1   0.722410  0.459473  0.821906\n",
       "0           50        10            2   0.702803  0.509643  0.824597\n",
       "0           50        10            3   0.696882  0.525688  0.825294\n",
       "0          100         4            1   0.825278  0.205055  0.791808\n",
       "0          100         4            2   0.746701  0.337876  0.806658\n",
       "0          100         4            3   0.728374  0.384435  0.811441\n",
       "0          100         6            1   0.777067  0.323838  0.808850\n",
       "0          100         6            2   0.747404  0.397271  0.816823\n",
       "0          100         6            3   0.728565  0.423363  0.817521\n",
       "0          100         8            1   0.752378  0.400491  0.818418\n",
       "0          100         8            2   0.727428  0.467101  0.824198\n",
       "0          100         8            3   0.716922  0.493583  0.825792\n",
       "0          100        10            1   0.727853  0.465895  0.824098\n",
       "0          100        10            2   0.707771  0.508838  0.825693\n",
       "0          100        10            3   0.702453  0.522877  0.826390\n",
       "0          500         4            1   0.816286  0.200245  0.790114\n",
       "0          500         4            2   0.744585  0.348320  0.808352\n",
       "0          500         4            3   0.729122  0.381626  0.811142\n",
       "0          500         6            1   0.767722  0.324642  0.807654\n",
       "0          500         6            2   0.743157  0.389247  0.814830\n",
       "0          500         6            3   0.728046  0.410517  0.815428\n",
       "0          500         8            1   0.754561  0.395263  0.817820\n",
       "0          500         8            2   0.731583  0.454259  0.823002\n",
       "0          500         8            3   0.718955  0.493184  0.826191\n",
       "0          500        10            1   0.727772  0.467500  0.824298\n",
       "0          500        10            2   0.715564  0.508031  0.827586\n",
       "0          500        10            3   0.695855  0.532912  0.825892"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Multiple Correspondence Analysis (MCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "\n",
    "# numero de arvores da random forest.\n",
    "n_estimators = [5,10,50,100,500]\n",
    "\n",
    "# profundidade maxima das arvores\n",
    "max_depth = [4,6,8,10]\n",
    "\n",
    "# numero maximo de caracteristicas a considerar.\n",
    "max_features = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome Arquivo Origem: adult_train_33.1_tratado_MCA.csv\n"
     ]
    }
   ],
   "source": [
    "# Nome do Dataset de Entrada\n",
    "ds_nome = 'adult_train_33.1'\n",
    "\n",
    "#Notebook 01-pre-proc_tratamento_base.ipynb prepara dados preciamente\n",
    "ds_pre_proc = '_tratado_MCA'\n",
    "ds_tipo = '.csv'\n",
    "ds_full_name = ds_nome + ds_pre_proc + ds_tipo\n",
    "\n",
    "print(\"Nome Arquivo Origem: {0}\".format(ds_full_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(ds_full_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10034, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNúmero de K: 3\u001b[0;0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_dicts = kFold(train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_dicts[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.082125</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>-0.074746</td>\n",
       "      <td>-0.006659</td>\n",
       "      <td>0.070368</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>-0.043017</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272706</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>-0.045254</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>-0.062299</td>\n",
       "      <td>-0.006852</td>\n",
       "      <td>-0.024369</td>\n",
       "      <td>-0.005436</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.062570</td>\n",
       "      <td>-0.012166</td>\n",
       "      <td>-0.077619</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>-0.048345</td>\n",
       "      <td>0.046914</td>\n",
       "      <td>-0.050294</td>\n",
       "      <td>0.051538</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042881</td>\n",
       "      <td>-0.145118</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>0.047566</td>\n",
       "      <td>-0.073234</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.093636</td>\n",
       "      <td>0.145880</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.043283</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.087173</td>\n",
       "      <td>-0.135152</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.056551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0 -0.082125  0.104588  0.069364 -0.074746 -0.006659  0.070368  0.003401   \n",
       "1  0.272706 -0.000564  0.025023 -0.045254  0.043857 -0.062299 -0.006852   \n",
       "2 -0.062570 -0.012166 -0.077619  0.012140 -0.048345  0.046914 -0.050294   \n",
       "3  0.042881 -0.145118 -0.043249  0.047566 -0.073234  0.036480  0.059404   \n",
       "4 -0.093636  0.145880  0.004478  0.043283  0.050437  0.020226  0.087173   \n",
       "\n",
       "          8         9        10  sal  \n",
       "0  0.011989 -0.043017  0.016424    0  \n",
       "1 -0.024369 -0.005436 -0.019910    0  \n",
       "2  0.051538  0.006365  0.019667    0  \n",
       "3  0.031942  0.061853  0.000136    0  \n",
       "4 -0.135152  0.020913  0.056551    0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.79951\n",
      "Recall: 0.15766\n",
      "Accuracy: 0.77785\n",
      "--- 0.9413411617279053 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.78683\n",
      "Recall: 0.27602\n",
      "Accuracy: 0.79958\n",
      "--- 0.5552263259887695 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.70169\n",
      "Recall: 0.45507\n",
      "Accuracy: 0.81623\n",
      "--- 0.606414794921875 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.76036\n",
      "Recall: 0.24314\n",
      "Accuracy: 0.79181\n",
      "--- 0.8269524574279785 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.7041\n",
      "Recall: 0.4715\n",
      "Accuracy: 0.81951\n",
      "--- 0.5416123867034912 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.69984\n",
      "Recall: 0.51043\n",
      "Accuracy: 0.8239\n",
      "--- 0.4689769744873047 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.72327\n",
      "Recall: 0.41935\n",
      "Accuracy: 0.81583\n",
      "--- 0.7874016761779785 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.68228\n",
      "Recall: 0.51445\n",
      "Accuracy: 0.81981\n",
      "--- 0.4331858158111572 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.67833\n",
      "Recall: 0.5309\n",
      "Accuracy: 0.82091\n",
      "--- 0.5075175762176514 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.67957\n",
      "Recall: 0.44663\n",
      "Accuracy: 0.81005\n",
      "--- 0.3105049133300781 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.67287\n",
      "Recall: 0.52047\n",
      "Accuracy: 0.81752\n",
      "--- 0.43717241287231445 time ---\n",
      "n_estimators:  5\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.6589\n",
      "Recall: 0.5365\n",
      "Accuracy: 0.81563\n",
      "--- 0.5309209823608398 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.67678\n",
      "Recall: 0.08068\n",
      "Accuracy: 0.7653\n",
      "--- 0.35280799865722656 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.77405\n",
      "Recall: 0.26847\n",
      "Accuracy: 0.79869\n",
      "--- 0.4850497245788574 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.73121\n",
      "Recall: 0.45024\n",
      "Accuracy: 0.82211\n",
      "--- 0.5942177772521973 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.76087\n",
      "Recall: 0.31983\n",
      "Accuracy: 0.80546\n",
      "--- 0.48110461235046387 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.7335\n",
      "Recall: 0.44102\n",
      "Accuracy: 0.82141\n",
      "--- 0.697857141494751 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.71659\n",
      "Recall: 0.49037\n",
      "Accuracy: 0.82509\n",
      "--- 0.9049828052520752 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.74514\n",
      "Recall: 0.38363\n",
      "Accuracy: 0.81403\n",
      "--- 0.5058629512786865 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.69801\n",
      "Recall: 0.52209\n",
      "Accuracy: 0.8244\n",
      "--- 0.7659263610839844 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.68918\n",
      "Recall: 0.52528\n",
      "Accuracy: 0.8232\n",
      "--- 1.190535306930542 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.69392\n",
      "Recall: 0.46629\n",
      "Accuracy: 0.81633\n",
      "--- 0.9765639305114746 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.6865\n",
      "Recall: 0.51285\n",
      "Accuracy: 0.82071\n",
      "--- 1.1104435920715332 time ---\n",
      "n_estimators:  10\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.67988\n",
      "Recall: 0.52848\n",
      "Accuracy: 0.82101\n",
      "--- 1.2737476825714111 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.80468\n",
      "Recall: 0.10715\n",
      "Accuracy: 0.77178\n",
      "--- 1.9120547771453857 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.78691\n",
      "Recall: 0.32222\n",
      "Accuracy: 0.80985\n",
      "--- 2.947465419769287 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.75616\n",
      "Recall: 0.41091\n",
      "Accuracy: 0.82051\n",
      "--- 4.386563062667847 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.78922\n",
      "Recall: 0.31662\n",
      "Accuracy: 0.80895\n",
      "--- 2.5282225608825684 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.74515\n",
      "Recall: 0.44783\n",
      "Accuracy: 0.8246\n",
      "--- 4.427100419998169 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.7283\n",
      "Recall: 0.48636\n",
      "Accuracy: 0.82709\n",
      "--- 4.471132755279541 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.74566\n",
      "Recall: 0.41091\n",
      "Accuracy: 0.81852\n",
      "--- 2.6489758491516113 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.71776\n",
      "Recall: 0.49357\n",
      "Accuracy: 0.82589\n",
      "--- 4.361561298370361 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.7097\n",
      "Recall: 0.52047\n",
      "Accuracy: 0.82779\n",
      "--- 5.069488763809204 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.72139\n",
      "Recall: 0.44944\n",
      "Accuracy: 0.82001\n",
      "--- 2.3236570358276367 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.70016\n",
      "Recall: 0.52729\n",
      "Accuracy: 0.82639\n",
      "--- 3.5246195793151855 time ---\n",
      "n_estimators:  50\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.68808\n",
      "Recall: 0.53692\n",
      "Accuracy: 0.8244\n",
      "--- 4.977061033248901 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.80092\n",
      "Recall: 0.10231\n",
      "Accuracy: 0.77038\n",
      "--- 4.466052770614624 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.78011\n",
      "Recall: 0.33788\n",
      "Accuracy: 0.81174\n",
      "--- 4.511835813522339 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.75342\n",
      "Recall: 0.41653\n",
      "Accuracy: 0.82091\n",
      "--- 6.746407508850098 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.79035\n",
      "Recall: 0.3126\n",
      "Accuracy: 0.80865\n",
      "--- 5.493194580078125 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.74531\n",
      "Recall: 0.44624\n",
      "Accuracy: 0.8244\n",
      "--- 7.002329111099243 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.7304\n",
      "Recall: 0.49358\n",
      "Accuracy: 0.82878\n",
      "--- 8.743807077407837 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.75801\n",
      "Recall: 0.41212\n",
      "Accuracy: 0.82121\n",
      "--- 5.1545867919921875 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.73081\n",
      "Recall: 0.49117\n",
      "Accuracy: 0.82848\n",
      "--- 11.499487400054932 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.71095\n",
      "Recall: 0.51203\n",
      "Accuracy: 0.82699\n",
      "--- 10.54272747039795 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.72366\n",
      "Recall: 0.45385\n",
      "Accuracy: 0.82121\n",
      "--- 5.950865983963013 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.70376\n",
      "Recall: 0.52127\n",
      "Accuracy: 0.82649\n",
      "--- 9.1722571849823 time ---\n",
      "n_estimators:  100\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.69389\n",
      "Recall: 0.53772\n",
      "Accuracy: 0.82609\n",
      "--- 11.719728708267212 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  1\n",
      "Precision: 0.79396\n",
      "Recall: 0.11556\n",
      "Accuracy: 0.77277\n",
      "--- 18.93995189666748 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  2\n",
      "Precision: 0.7754\n",
      "Recall: 0.34992\n",
      "Accuracy: 0.81304\n",
      "--- 28.339628219604492 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  4\n",
      "max_features:  3\n",
      "Precision: 0.74982\n",
      "Recall: 0.42617\n",
      "Accuracy: 0.82191\n",
      "--- 26.260777950286865 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  1\n",
      "Precision: 0.79203\n",
      "Recall: 0.30899\n",
      "Accuracy: 0.80795\n",
      "--- 23.944475889205933 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  2\n",
      "Precision: 0.74958\n",
      "Recall: 0.45225\n",
      "Accuracy: 0.82619\n",
      "--- 26.063826322555542 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  6\n",
      "max_features:  3\n",
      "Precision: 0.73188\n",
      "Recall: 0.48636\n",
      "Accuracy: 0.82799\n",
      "--- 41.09595704078674 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  1\n",
      "Precision: 0.76543\n",
      "Recall: 0.39928\n",
      "Accuracy: 0.82031\n",
      "--- 29.6515474319458 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  2\n",
      "Precision: 0.72387\n",
      "Recall: 0.49117\n",
      "Accuracy: 0.82689\n",
      "--- 38.874502658843994 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  8\n",
      "max_features:  3\n",
      "Precision: 0.71525\n",
      "Recall: 0.50883\n",
      "Accuracy: 0.82759\n",
      "--- 56.36936283111572 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  1\n",
      "Precision: 0.73265\n",
      "Recall: 0.45826\n",
      "Accuracy: 0.8237\n",
      "--- 27.13492512702942 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  2\n",
      "Precision: 0.70791\n",
      "Recall: 0.52207\n",
      "Accuracy: 0.82749\n",
      "--- 34.99264717102051 time ---\n",
      "n_estimators:  500\n",
      "max_depth:  10\n",
      "max_features:  3\n",
      "Precision: 0.69503\n",
      "Recall: 0.53812\n",
      "Accuracy: 0.82649\n",
      "--- 49.515833616256714 time ---\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "columns = ['n_estimators', 'max_depth', 'max_features', 'precision', 'recall', 'acuracia']\n",
    "res_mca = pd.DataFrame(columns = columns)\n",
    "best_precision = {'score': 0, 'model': None}\n",
    "best_recall = {'score': 0, 'model': None}\n",
    "best_accuracy = {'score': 0, 'model': None}\n",
    "\n",
    "for i_ne in range(0, len(n_estimators)):\n",
    "    for i_md in range(0, len(max_depth)):\n",
    "        for i_mf in range(0, len(max_features)):\n",
    "            print(\"n_estimators: \", n_estimators[i_ne])\n",
    "            print(\"max_depth: \", max_depth[i_md])\n",
    "            print(\"max_features: \", max_features[i_mf])\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators[i_ne], max_depth=max_depth[i_md], max_features=max_features[i_mf])\n",
    "\n",
    "            precision, recall, acuracia = classification(kfold_dicts_mca, model)\n",
    "            if precision > best_precision['score']:\n",
    "                best_precision['score'] = precision\n",
    "                best_precision['model'] = model\n",
    "            if recall > best_recall['score']:\n",
    "                best_recall['score'] = recall\n",
    "                best_recall['model'] = model\n",
    "            if acuracia > best_accuracy['score']:\n",
    "                best_accuracy['score'] = acuracia\n",
    "                best_accuracy['model'] = model\n",
    "            res_mca = pd.concat([res_mca, pd.DataFrame([[n_estimators[i_ne], max_depth[i_md], max_features[i_mf],\n",
    "                                                 precision, recall, acuracia]], columns = columns)]) \n",
    "            #res = pd.concat([res, pd.DataFrame([n_estimators[i_ne],max_features[i_mf],precision, recall, acuracia], columns = columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>acuracia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.157659</td>\n",
       "      <td>0.777854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786834</td>\n",
       "      <td>0.276024</td>\n",
       "      <td>0.799579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.701695</td>\n",
       "      <td>0.455069</td>\n",
       "      <td>0.816225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760359</td>\n",
       "      <td>0.243143</td>\n",
       "      <td>0.791807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704101</td>\n",
       "      <td>0.471499</td>\n",
       "      <td>0.819513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.699840</td>\n",
       "      <td>0.510427</td>\n",
       "      <td>0.823899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723271</td>\n",
       "      <td>0.419349</td>\n",
       "      <td>0.815826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682277</td>\n",
       "      <td>0.514453</td>\n",
       "      <td>0.819813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.678330</td>\n",
       "      <td>0.530903</td>\n",
       "      <td>0.820909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679571</td>\n",
       "      <td>0.446633</td>\n",
       "      <td>0.810046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.672867</td>\n",
       "      <td>0.520469</td>\n",
       "      <td>0.817520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.658901</td>\n",
       "      <td>0.536502</td>\n",
       "      <td>0.815627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.676781</td>\n",
       "      <td>0.080682</td>\n",
       "      <td>0.765299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.774054</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>0.798685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731212</td>\n",
       "      <td>0.450243</td>\n",
       "      <td>0.822105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760869</td>\n",
       "      <td>0.319831</td>\n",
       "      <td>0.805462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733505</td>\n",
       "      <td>0.441020</td>\n",
       "      <td>0.821408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716593</td>\n",
       "      <td>0.490366</td>\n",
       "      <td>0.825095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745144</td>\n",
       "      <td>0.383631</td>\n",
       "      <td>0.814032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.698014</td>\n",
       "      <td>0.522090</td>\n",
       "      <td>0.824397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.689179</td>\n",
       "      <td>0.525278</td>\n",
       "      <td>0.823201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693916</td>\n",
       "      <td>0.466295</td>\n",
       "      <td>0.816325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.686501</td>\n",
       "      <td>0.512848</td>\n",
       "      <td>0.820710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.679879</td>\n",
       "      <td>0.528485</td>\n",
       "      <td>0.821008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804679</td>\n",
       "      <td>0.107149</td>\n",
       "      <td>0.771776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786912</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.809846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.756156</td>\n",
       "      <td>0.410909</td>\n",
       "      <td>0.820510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.316616</td>\n",
       "      <td>0.808950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745146</td>\n",
       "      <td>0.447833</td>\n",
       "      <td>0.824597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728299</td>\n",
       "      <td>0.486362</td>\n",
       "      <td>0.827088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745664</td>\n",
       "      <td>0.410911</td>\n",
       "      <td>0.818517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.717764</td>\n",
       "      <td>0.493572</td>\n",
       "      <td>0.825892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709704</td>\n",
       "      <td>0.520466</td>\n",
       "      <td>0.827786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721392</td>\n",
       "      <td>0.449443</td>\n",
       "      <td>0.820012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700164</td>\n",
       "      <td>0.527287</td>\n",
       "      <td>0.826390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.688077</td>\n",
       "      <td>0.536915</td>\n",
       "      <td>0.824397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800916</td>\n",
       "      <td>0.102308</td>\n",
       "      <td>0.770380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.780105</td>\n",
       "      <td>0.337882</td>\n",
       "      <td>0.811740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.753420</td>\n",
       "      <td>0.416532</td>\n",
       "      <td>0.820909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.312604</td>\n",
       "      <td>0.808651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745314</td>\n",
       "      <td>0.446236</td>\n",
       "      <td>0.824397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.730397</td>\n",
       "      <td>0.493582</td>\n",
       "      <td>0.828782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758009</td>\n",
       "      <td>0.412117</td>\n",
       "      <td>0.821208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730808</td>\n",
       "      <td>0.491169</td>\n",
       "      <td>0.828483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.710946</td>\n",
       "      <td>0.512035</td>\n",
       "      <td>0.826988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723665</td>\n",
       "      <td>0.453855</td>\n",
       "      <td>0.821208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.703755</td>\n",
       "      <td>0.521269</td>\n",
       "      <td>0.826490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693892</td>\n",
       "      <td>0.537724</td>\n",
       "      <td>0.826092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793963</td>\n",
       "      <td>0.115561</td>\n",
       "      <td>0.772772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775404</td>\n",
       "      <td>0.349921</td>\n",
       "      <td>0.813036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.821906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792033</td>\n",
       "      <td>0.308989</td>\n",
       "      <td>0.807953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.749577</td>\n",
       "      <td>0.452247</td>\n",
       "      <td>0.826191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0.486358</td>\n",
       "      <td>0.827985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765426</td>\n",
       "      <td>0.399277</td>\n",
       "      <td>0.820311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.723873</td>\n",
       "      <td>0.491171</td>\n",
       "      <td>0.826889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.715251</td>\n",
       "      <td>0.508828</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732651</td>\n",
       "      <td>0.458263</td>\n",
       "      <td>0.823699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707909</td>\n",
       "      <td>0.522072</td>\n",
       "      <td>0.827487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695030</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>0.826490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators max_depth max_features  precision    recall  acuracia\n",
       "0            5         4            1   0.799509  0.157659  0.777854\n",
       "0            5         4            2   0.786834  0.276024  0.799579\n",
       "0            5         4            3   0.701695  0.455069  0.816225\n",
       "0            5         6            1   0.760359  0.243143  0.791807\n",
       "0            5         6            2   0.704101  0.471499  0.819513\n",
       "0            5         6            3   0.699840  0.510427  0.823899\n",
       "0            5         8            1   0.723271  0.419349  0.815826\n",
       "0            5         8            2   0.682277  0.514453  0.819813\n",
       "0            5         8            3   0.678330  0.530903  0.820909\n",
       "0            5        10            1   0.679571  0.446633  0.810046\n",
       "0            5        10            2   0.672867  0.520469  0.817520\n",
       "0            5        10            3   0.658901  0.536502  0.815627\n",
       "0           10         4            1   0.676781  0.080682  0.765299\n",
       "0           10         4            2   0.774054  0.268474  0.798685\n",
       "0           10         4            3   0.731212  0.450243  0.822105\n",
       "0           10         6            1   0.760869  0.319831  0.805462\n",
       "0           10         6            2   0.733505  0.441020  0.821408\n",
       "0           10         6            3   0.716593  0.490366  0.825095\n",
       "0           10         8            1   0.745144  0.383631  0.814032\n",
       "0           10         8            2   0.698014  0.522090  0.824397\n",
       "0           10         8            3   0.689179  0.525278  0.823201\n",
       "0           10        10            1   0.693916  0.466295  0.816325\n",
       "0           10        10            2   0.686501  0.512848  0.820710\n",
       "0           10        10            3   0.679879  0.528485  0.821008\n",
       "0           50         4            1   0.804679  0.107149  0.771776\n",
       "0           50         4            2   0.786912  0.322222  0.809846\n",
       "0           50         4            3   0.756156  0.410909  0.820510\n",
       "0           50         6            1   0.789216  0.316616  0.808950\n",
       "0           50         6            2   0.745146  0.447833  0.824597\n",
       "0           50         6            3   0.728299  0.486362  0.827088\n",
       "0           50         8            1   0.745664  0.410911  0.818517\n",
       "0           50         8            2   0.717764  0.493572  0.825892\n",
       "0           50         8            3   0.709704  0.520466  0.827786\n",
       "0           50        10            1   0.721392  0.449443  0.820012\n",
       "0           50        10            2   0.700164  0.527287  0.826390\n",
       "0           50        10            3   0.688077  0.536915  0.824397\n",
       "0          100         4            1   0.800916  0.102308  0.770380\n",
       "0          100         4            2   0.780105  0.337882  0.811740\n",
       "0          100         4            3   0.753420  0.416532  0.820909\n",
       "0          100         6            1   0.790353  0.312604  0.808651\n",
       "0          100         6            2   0.745314  0.446236  0.824397\n",
       "0          100         6            3   0.730397  0.493582  0.828782\n",
       "0          100         8            1   0.758009  0.412117  0.821208\n",
       "0          100         8            2   0.730808  0.491169  0.828483\n",
       "0          100         8            3   0.710946  0.512035  0.826988\n",
       "0          100        10            1   0.723665  0.453855  0.821208\n",
       "0          100        10            2   0.703755  0.521269  0.826490\n",
       "0          100        10            3   0.693892  0.537724  0.826092\n",
       "0          500         4            1   0.793963  0.115561  0.772772\n",
       "0          500         4            2   0.775404  0.349921  0.813036\n",
       "0          500         4            3   0.749817  0.426166  0.821906\n",
       "0          500         6            1   0.792033  0.308989  0.807953\n",
       "0          500         6            2   0.749577  0.452247  0.826191\n",
       "0          500         6            3   0.731878  0.486358  0.827985\n",
       "0          500         8            1   0.765426  0.399277  0.820311\n",
       "0          500         8            2   0.723873  0.491171  0.826889\n",
       "0          500         8            3   0.715251  0.508828  0.827586\n",
       "0          500        10            1   0.732651  0.458263  0.823699\n",
       "0          500        10            2   0.707909  0.522072  0.827487\n",
       "0          500        10            3   0.695030  0.538119  0.826490"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_mca.head(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
